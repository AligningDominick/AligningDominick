
### 🌐 Aligning Dominick | Language meets safety at scale

I design stress tests for large language models — not in theory, but in 25+ languages that people actually speak, with risks that actually matter.

From the Swahili classroom to an Amharic health hotline, my work builds contextual evaluations that ask not just *“Is this aligned?”* but *“Is this aligned for her, in this language, under these stakes?”*

📍 I specialize in:
- Building multilingual safety probes rooted in real-world vignettes
- Evaluating refusal consistency, jailbreak resilience, and compliance risk
- Mapping typologically diverse language behavior to alignment metrics

My projects are open-source, reproducible, and designed for practical impact in frontier alignment.

#### ✳️ Featured Repository  
**[LLM-RiskScenes](https://github.com/AligningDominick/llm-riskscenes)**  
*Stress-testing Claude, GPT-4 and Cohere using multilingual real-world contexts across healthcare, education, and civil discourse.*

---

### 🧭 Vision

Safer models won’t be built in just one language.

Alignment must scale — linguistically, culturally, and ethically.  
My research exists to make that scaling measurable, accountable, and community-driven.

---

📫 dominickaligning@gmail.com  
🌍 Projects welcome | Multilingual collaboration encouraged
